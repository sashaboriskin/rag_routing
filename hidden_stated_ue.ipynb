{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d000ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "from utils import transfer_context_prompt\n",
    "\n",
    "import warnings\n",
    "from transformers import logging as transformers_logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "transformers_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4942e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/share/nlp/chitchat/models/Llama-3.2-3B-Instruct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac59a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d15919ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35904293",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Who won season 10 of dancing with the stars?'\n",
    "context = 'The story, illustrated by the author, is set in England as the Black Death (bubonic plague) is sweeping across the country. Young Robin is sent away to become a knight like his father, but his dreams are endangered when he loses the use of his legs. A doctor reassures Robin that the weakness in his legs is not caused by the plague and the doctor is supposed to come and help him but does not. His parents are away, serving the king and queen during war, and the servants abandon the house, fearing the plague. Robin is saved by Brother Luke, a friar, who finds him and takes him to a monastery and cares for him.'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": transfer_context_prompt(question, context)}, \n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant who gives only factually correct short answers without additional information\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3312c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "884eac89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 07 Nov 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nAnswer the question Who won season 10 of dancing with the stars? based on the given context The story, illustrated by the author, is set in England as the Black Death (bubonic plague) is sweeping across the country. Young Robin is sent away to become a knight like his father, but his dreams are endangered when he loses the use of his legs. A doctor reassures Robin that the weakness in his legs is not caused by the plague and the doctor is supposed to come and help him but does not. His parents are away, serving the king and queen during war, and the servants abandon the house, fearing the plague. Robin is saved by Brother Luke, a friar, who finds him and takes him to a monastery and cares for him.<|eot_id|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful assistant who gives only factually correct short answers without additional information<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9ecc6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'system\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 07 Nov 2024\\n\\nuser\\n\\nAnswer the question Who won season 10 of dancing with the stars? based on the given context The story, illustrated by the author, is set in England as the Black Death (bubonic plague) is sweeping across the country. Young Robin is sent away to become a knight like his father, but his dreams are endangered when he loses the use of his legs. A doctor reassures Robin that the weakness in his legs is not caused by the plague and the doctor is supposed to come and help him but does not. His parents are away, serving the king and queen during war, and the servants abandon the house, fearing the plague. Robin is saved by Brother Luke, a friar, who finds him and takes him to a monastery and cares for him.system\\n\\nYou are a helpful assistant who gives only factually correct short answers without additional informationassistant\\n\\nThere is no information about the TV show \"Dancing with the Stars\" in the given context.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(\n",
    "    model.generate(**tokenizer(text, return_tensors='pt').to(device), \n",
    "                   max_new_tokens=100)[0], \n",
    "    skip_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57acb315",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5adeeecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_token(activations, model, tokenizer):\n",
    "    logit_lens = {}\n",
    "    for name, activation in activations.items():\n",
    "        lm_head_out = model.lm_head(model.model.norm(activation))\n",
    "        next_logits = lm_head_out[:, -1, :]\n",
    "        logit_lens[name] = tokenizer.decode(torch.argmax(next_logits).item(), skip_special_tokens=True)\n",
    "    return logit_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7185bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(input_text, model, tokenizer, max_new_tokens=1):\n",
    "    device = model.device\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    input_ids, attention_mask = inputs[\"input_ids\"].to(device), inputs[\"attention_mask\"].to(device)\n",
    "    \n",
    "    def getActivation(name):\n",
    "        # the hook signature\n",
    "        def hook(model, input, output):\n",
    "            activations[name + \"_output\"] = output[0].detach()\n",
    "\n",
    "        return hook\n",
    "    \n",
    "    h = [\n",
    "        model.model.layers[i].register_forward_hook(getActivation(f\"layers_{i}\")) \n",
    "        for i in range(model.config.num_hidden_layers)\n",
    "    ]\n",
    "    \n",
    "    logit_lens = {}\n",
    "    for i_token in range(max_new_tokens):\n",
    "        activations = {}\n",
    "        sampling_params = GenerationConfig(\n",
    "            temperature=0.6,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "            do_sample=False,\n",
    "            num_beams=1,\n",
    "            presence_penalty=0.0,\n",
    "            repetition_penalty=1.0,\n",
    "            generate_until=(),\n",
    "            allow_newlines=True,\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids, attention_mask=attention_mask, generation_config=sampling_params)\n",
    "        logits, past_key_values = out.values()\n",
    "        next_logits = logits[:, -1, :]\n",
    "        next_token_id = torch.argmax(next_logits)\n",
    "        input_ids = torch.cat((input_ids, torch.tensor([[next_token_id]], device=device)), dim=1)\n",
    "        attention_mask = torch.cat((attention_mask, torch.tensor([[1]], device=device)), dim=1)\n",
    "        logit_lens[i_token] = get_next_token(activations, model, tokenizer)\n",
    "    \n",
    "    [hook.remove() for hook in h]\n",
    "    return logit_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2b224a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e86c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_per_layer = get_activation(text, model, tokenizer, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5906a002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>layers_0_output</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>I</td>\n",
       "      <td>don</td>\n",
       "      <td>'t</td>\n",
       "      <td>have</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>Season</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>with</td>\n",
       "      <td>the</td>\n",
       "      <td>Stars</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_1_output</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>I</td>\n",
       "      <td>don</td>\n",
       "      <td>'t</td>\n",
       "      <td>have</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>Season</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>with</td>\n",
       "      <td>the</td>\n",
       "      <td>Stars</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_2_output</th>\n",
       "      <td>idges</td>\n",
       "      <td>I</td>\n",
       "      <td>don</td>\n",
       "      <td>'t</td>\n",
       "      <td>have</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>Season</td>\n",
       "      <td>racks</td>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>WITH</td>\n",
       "      <td>gusto</td>\n",
       "      <td>Stars</td>\n",
       "      <td>weighed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_3_output</th>\n",
       "      <td>enic</td>\n",
       "      <td>I</td>\n",
       "      <td>don</td>\n",
       "      <td>'t</td>\n",
       "      <td>ares</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>Season</td>\n",
       "      <td>Season</td>\n",
       "      <td>10</td>\n",
       "      <td>Of</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>-with</td>\n",
       "      <td>Enabled</td>\n",
       "      <td>Stars</td>\n",
       "      <td>gaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_4_output</th>\n",
       "      <td>ーン</td>\n",
       "      <td>I</td>\n",
       "      <td>究</td>\n",
       "      <td>'t</td>\n",
       "      <td>alone</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>season</td>\n",
       "      <td>ago</td>\n",
       "      <td>10</td>\n",
       "      <td>iang</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>-with</td>\n",
       "      <td>Swan</td>\n",
       "      <td>Stars</td>\n",
       "      <td>UNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_5_output</th>\n",
       "      <td>olor</td>\n",
       "      <td>/we</td>\n",
       "      <td>ераль</td>\n",
       "      <td>necessarily</td>\n",
       "      <td>عات</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>season</td>\n",
       "      <td>(Program</td>\n",
       "      <td>10</td>\n",
       "      <td>afa</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>placer</td>\n",
       "      <td>antium</td>\n",
       "      <td>star</td>\n",
       "      <td>nor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_6_output</th>\n",
       "      <td>rough</td>\n",
       "      <td>'d</td>\n",
       "      <td>fairy</td>\n",
       "      <td>currently</td>\n",
       "      <td>slightest</td>\n",
       "      <td>information</td>\n",
       "      <td>co</td>\n",
       "      <td>season</td>\n",
       "      <td>nell</td>\n",
       "      <td>Ranch</td>\n",
       "      <td>-round</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>Congress</td>\n",
       "      <td>well</td>\n",
       "      <td>rim</td>\n",
       "      <td>rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_7_output</th>\n",
       "      <td>tap</td>\n",
       "      <td>'ve</td>\n",
       "      <td>caffeine</td>\n",
       "      <td>Forbidden</td>\n",
       "      <td>yet</td>\n",
       "      <td>information</td>\n",
       "      <td>HostException</td>\n",
       "      <td>season</td>\n",
       "      <td>otify</td>\n",
       "      <td>unconventional</td>\n",
       "      <td>this</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>gence</td>\n",
       "      <td>specificity</td>\n",
       "      <td>rim</td>\n",
       "      <td>otr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_8_output</th>\n",
       "      <td>Din</td>\n",
       "      <td>outr</td>\n",
       "      <td>REATE</td>\n",
       "      <td>upo</td>\n",
       "      <td>contained</td>\n",
       "      <td>conosc</td>\n",
       "      <td>-how</td>\n",
       "      <td>season</td>\n",
       "      <td>的心</td>\n",
       "      <td>Feinstein</td>\n",
       "      <td>osl</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>ーツ</td>\n",
       "      <td>gang</td>\n",
       "      <td>ssc</td>\n",
       "      <td>hereby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_9_output</th>\n",
       "      <td>Courtesy</td>\n",
       "      <td>hereby</td>\n",
       "      <td>inne</td>\n",
       "      <td>currently</td>\n",
       "      <td>anymore</td>\n",
       "      <td>ledged</td>\n",
       "      <td>centralized</td>\n",
       "      <td>ização</td>\n",
       "      <td>uada</td>\n",
       "      <td>aghan</td>\n",
       "      <td>chwitz</td>\n",
       "      <td>Himal</td>\n",
       "      <td>bash</td>\n",
       "      <td>Dirty</td>\n",
       "      <td>monumental</td>\n",
       "      <td>중에</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_10_output</th>\n",
       "      <td>dup</td>\n",
       "      <td>/we</td>\n",
       "      <td>enic</td>\n",
       "      <td>Asc</td>\n",
       "      <td>Fant</td>\n",
       "      <td>nor</td>\n",
       "      <td>specifically</td>\n",
       "      <td>wrought</td>\n",
       "      <td>face</td>\n",
       "      <td>edition</td>\n",
       "      <td>gger</td>\n",
       "      <td>orte</td>\n",
       "      <td>ponent</td>\n",
       "      <td>Broken</td>\n",
       "      <td>ropol</td>\n",
       "      <td>modity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_11_output</th>\n",
       "      <td>Din</td>\n",
       "      <td>hereby</td>\n",
       "      <td>ardon</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>slightest</td>\n",
       "      <td>nor</td>\n",
       "      <td>afort</td>\n",
       "      <td>-season</td>\n",
       "      <td>ift</td>\n",
       "      <td>ention</td>\n",
       "      <td>feeder</td>\n",
       "      <td>opposite</td>\n",
       "      <td>capital</td>\n",
       "      <td>sine</td>\n",
       "      <td>ropol</td>\n",
       "      <td>bombed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_12_output</th>\n",
       "      <td>nothing</td>\n",
       "      <td>hereby</td>\n",
       "      <td>ovah</td>\n",
       "      <td>/no</td>\n",
       "      <td>Cot</td>\n",
       "      <td>directly</td>\n",
       "      <td>specifically</td>\n",
       "      <td>治</td>\n",
       "      <td>debuted</td>\n",
       "      <td>specifically</td>\n",
       "      <td>ething</td>\n",
       "      <td>influential</td>\n",
       "      <td>busted</td>\n",
       "      <td>конкрет</td>\n",
       "      <td>debuted</td>\n",
       "      <td>instead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_13_output</th>\n",
       "      <td>Answer</td>\n",
       "      <td>actually</td>\n",
       "      <td>.wikipedia</td>\n",
       "      <td>currently</td>\n",
       "      <td>directly</td>\n",
       "      <td>except</td>\n",
       "      <td>�</td>\n",
       "      <td>season</td>\n",
       "      <td>Loud</td>\n",
       "      <td>specifically</td>\n",
       "      <td>podium</td>\n",
       "      <td>awards</td>\n",
       "      <td>�</td>\n",
       "      <td>人民共和国</td>\n",
       "      <td>provision</td>\n",
       "      <td>instead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_14_output</th>\n",
       "      <td>Answer</td>\n",
       "      <td>neither</td>\n",
       "      <td>answer</td>\n",
       "      <td>yet</td>\n",
       "      <td>yet</td>\n",
       "      <td>about</td>\n",
       "      <td>/how</td>\n",
       "      <td>season</td>\n",
       "      <td>ertain</td>\n",
       "      <td>specifically</td>\n",
       "      <td>podium</td>\n",
       "      <td>hausen</td>\n",
       "      <td>Af</td>\n",
       "      <td>underlying</td>\n",
       "      <td>regarding</td>\n",
       "      <td>instead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_15_output</th>\n",
       "      <td>descon</td>\n",
       "      <td>actually</td>\n",
       "      <td>answer</td>\n",
       "      <td>provided</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>either</td>\n",
       "      <td>-specific</td>\n",
       "      <td>ษ</td>\n",
       "      <td>specifically</td>\n",
       "      <td>television</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>television</td>\n",
       "      <td>authoritative</td>\n",
       "      <td>regarding</td>\n",
       "      <td>swer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_16_output</th>\n",
       "      <td>information</td>\n",
       "      <td>couldn</td>\n",
       "      <td>nothing</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>/how</td>\n",
       "      <td>-specific</td>\n",
       "      <td>ษ</td>\n",
       "      <td>of</td>\n",
       "      <td>дан</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>contestants</td>\n",
       "      <td>acronym</td>\n",
       "      <td>-related</td>\n",
       "      <td>therefore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_17_output</th>\n",
       "      <td>information</td>\n",
       "      <td>couldn</td>\n",
       "      <td>nothing</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>how</td>\n",
       "      <td>-specific</td>\n",
       "      <td>contestants</td>\n",
       "      <td>of</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>authoritative</td>\n",
       "      <td>nor</td>\n",
       "      <td>uggest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_18_output</th>\n",
       "      <td>information</td>\n",
       "      <td>couldn</td>\n",
       "      <td>unfortunately</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>who</td>\n",
       "      <td>-specific</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>of</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>dancing</td>\n",
       "      <td>stars</td>\n",
       "      <td>nor</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_19_output</th>\n",
       "      <td>information</td>\n",
       "      <td>cannot</td>\n",
       "      <td>sorry</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>who</td>\n",
       "      <td>-specific</td>\n",
       "      <td>amateur</td>\n",
       "      <td>winners</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>with</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>stars</td>\n",
       "      <td>winner</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_20_output</th>\n",
       "      <td>there</td>\n",
       "      <td>cannot</td>\n",
       "      <td>'t</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>season</td>\n",
       "      <td>-specific</td>\n",
       "      <td>tenth</td>\n",
       "      <td>winner</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>dance</td>\n",
       "      <td>stars</td>\n",
       "      <td>winner</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_21_output</th>\n",
       "      <td>there</td>\n",
       "      <td>cannot</td>\n",
       "      <td>'t</td>\n",
       "      <td>have</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>season</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>winner</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>dance</td>\n",
       "      <td>stars</td>\n",
       "      <td>winner</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_22_output</th>\n",
       "      <td>there</td>\n",
       "      <td>couldn</td>\n",
       "      <td>'t</td>\n",
       "      <td>have</td>\n",
       "      <td>enough</td>\n",
       "      <td>about</td>\n",
       "      <td>season</td>\n",
       "      <td>ten</td>\n",
       "      <td>10</td>\n",
       "      <td>winner</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>with</td>\n",
       "      <td>stars</td>\n",
       "      <td>stars</td>\n",
       "      <td>winner</td>\n",
       "      <td>Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_23_output</th>\n",
       "      <td>there</td>\n",
       "      <td>couldn</td>\n",
       "      <td>'t</td>\n",
       "      <td>have</td>\n",
       "      <td>enough</td>\n",
       "      <td>about</td>\n",
       "      <td>Season</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>winner</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>with</td>\n",
       "      <td>stars</td>\n",
       "      <td>stars</td>\n",
       "      <td>winner</td>\n",
       "      <td>Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_24_output</th>\n",
       "      <td>there</td>\n",
       "      <td>don</td>\n",
       "      <td>'t</td>\n",
       "      <td>have</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>Season</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>with</td>\n",
       "      <td>the</td>\n",
       "      <td>Stars</td>\n",
       "      <td>.</td>\n",
       "      <td>Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_25_output</th>\n",
       "      <td>I</td>\n",
       "      <td>don</td>\n",
       "      <td>'t</td>\n",
       "      <td>have</td>\n",
       "      <td>enough</td>\n",
       "      <td>about</td>\n",
       "      <td>season</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>with</td>\n",
       "      <td>the</td>\n",
       "      <td>Stars</td>\n",
       "      <td>.</td>\n",
       "      <td>Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_26_output</th>\n",
       "      <td>There</td>\n",
       "      <td>don</td>\n",
       "      <td>'t</td>\n",
       "      <td>have</td>\n",
       "      <td>that</td>\n",
       "      <td>on</td>\n",
       "      <td>season</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>with</td>\n",
       "      <td>the</td>\n",
       "      <td>stars</td>\n",
       "      <td>.</td>\n",
       "      <td>Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers_27_output</th>\n",
       "      <td>I</td>\n",
       "      <td>don</td>\n",
       "      <td>'t</td>\n",
       "      <td>have</td>\n",
       "      <td>information</td>\n",
       "      <td>about</td>\n",
       "      <td>Season</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>with</td>\n",
       "      <td>the</td>\n",
       "      <td>Stars</td>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0          1               2             3   \\\n",
       "layers_0_output           \\n\\n          I             don            't   \n",
       "layers_1_output           \\n\\n          I             don            't   \n",
       "layers_2_output          idges          I             don            't   \n",
       "layers_3_output           enic          I             don            't   \n",
       "layers_4_output             ーン          I               究            't   \n",
       "layers_5_output           olor        /we           ераль   necessarily   \n",
       "layers_6_output          rough         'd           fairy     currently   \n",
       "layers_7_output            tap        've        caffeine     Forbidden   \n",
       "layers_8_output            Din       outr           REATE           upo   \n",
       "layers_9_output       Courtesy     hereby            inne     currently   \n",
       "layers_10_output           dup        /we            enic           Asc   \n",
       "layers_11_output           Din     hereby           ardon       Foreign   \n",
       "layers_12_output       nothing     hereby            ovah           /no   \n",
       "layers_13_output        Answer   actually      .wikipedia     currently   \n",
       "layers_14_output        Answer    neither          answer           yet   \n",
       "layers_15_output        descon   actually          answer      provided   \n",
       "layers_16_output   information     couldn         nothing   information   \n",
       "layers_17_output   information     couldn         nothing   information   \n",
       "layers_18_output   information     couldn   unfortunately   information   \n",
       "layers_19_output   information     cannot           sorry   information   \n",
       "layers_20_output         there     cannot              't   information   \n",
       "layers_21_output         there     cannot              't          have   \n",
       "layers_22_output         there     couldn              't          have   \n",
       "layers_23_output         there     couldn              't          have   \n",
       "layers_24_output         there        don              't          have   \n",
       "layers_25_output             I        don              't          have   \n",
       "layers_26_output         There        don              't          have   \n",
       "layers_27_output             I        don              't          have   \n",
       "\n",
       "                            4             5              6          7   \\\n",
       "layers_0_output           have   information          about     Season   \n",
       "layers_1_output           have   information          about     Season   \n",
       "layers_2_output           have   information          about     Season   \n",
       "layers_3_output           ares   information          about     Season   \n",
       "layers_4_output          alone   information          about     season   \n",
       "layers_5_output            عات   information          about     season   \n",
       "layers_6_output      slightest   information             co     season   \n",
       "layers_7_output            yet   information  HostException     season   \n",
       "layers_8_output      contained        conosc           -how     season   \n",
       "layers_9_output        anymore        ledged    centralized     ização   \n",
       "layers_10_output          Fant           nor   specifically    wrought   \n",
       "layers_11_output     slightest           nor          afort    -season   \n",
       "layers_12_output           Cot      directly   specifically          治   \n",
       "layers_13_output      directly        except              �     season   \n",
       "layers_14_output           yet         about           /how     season   \n",
       "layers_15_output   information         about         either  -specific   \n",
       "layers_16_output   information         about           /how  -specific   \n",
       "layers_17_output   information         about            how  -specific   \n",
       "layers_18_output   information         about            who  -specific   \n",
       "layers_19_output   information         about            who  -specific   \n",
       "layers_20_output   information         about         season  -specific   \n",
       "layers_21_output   information         about         season         10   \n",
       "layers_22_output        enough         about         season        ten   \n",
       "layers_23_output        enough         about         Season              \n",
       "layers_24_output   information         about         Season              \n",
       "layers_25_output        enough         about         season              \n",
       "layers_26_output          that            on         season              \n",
       "layers_27_output   information         about         Season              \n",
       "\n",
       "                            8                9            10            11  \\\n",
       "layers_0_output                              10           of       Dancing   \n",
       "layers_1_output                              10           of       Dancing   \n",
       "layers_2_output          racks               10           of       Dancing   \n",
       "layers_3_output         Season               10           Of       Dancing   \n",
       "layers_4_output            ago               10         iang       Dancing   \n",
       "layers_5_output       (Program               10          afa       Dancing   \n",
       "layers_6_output           nell            Ranch       -round       Dancing   \n",
       "layers_7_output          otify   unconventional         this       Dancing   \n",
       "layers_8_output             的心        Feinstein          osl       Dancing   \n",
       "layers_9_output           uada            aghan       chwitz         Himal   \n",
       "layers_10_output          face          edition         gger          orte   \n",
       "layers_11_output           ift           ention       feeder      opposite   \n",
       "layers_12_output       debuted     specifically       ething   influential   \n",
       "layers_13_output          Loud     specifically       podium        awards   \n",
       "layers_14_output        ertain     specifically       podium        hausen   \n",
       "layers_15_output             ษ     specifically   television       Dancing   \n",
       "layers_16_output             ษ               of          дан       Dancing   \n",
       "layers_17_output   contestants               of      Dancing       Dancing   \n",
       "layers_18_output       Dancing               of      Dancing       Dancing   \n",
       "layers_19_output       amateur          winners      Dancing          with   \n",
       "layers_20_output         tenth           winner      Dancing       Dancing   \n",
       "layers_21_output            10           winner      Dancing       Dancing   \n",
       "layers_22_output            10           winner      Dancing          with   \n",
       "layers_23_output            10           winner      Dancing          with   \n",
       "layers_24_output            10               of      Dancing          with   \n",
       "layers_25_output            10               of      Dancing          with   \n",
       "layers_26_output            10               of      Dancing          with   \n",
       "layers_27_output            10               of      Dancing          with   \n",
       "\n",
       "                            12              13           14          15  \n",
       "layers_0_output           with             the        Stars           .  \n",
       "layers_1_output           with             the        Stars           .  \n",
       "layers_2_output           WITH           gusto        Stars     weighed  \n",
       "layers_3_output          -with         Enabled        Stars         gaz  \n",
       "layers_4_output          -with            Swan        Stars         UNC  \n",
       "layers_5_output         placer          antium         star         nor  \n",
       "layers_6_output       Congress            well          rim          rn  \n",
       "layers_7_output          gence     specificity          rim         otr  \n",
       "layers_8_output             ーツ            gang          ssc      hereby  \n",
       "layers_9_output           bash           Dirty   monumental          중에  \n",
       "layers_10_output        ponent          Broken        ropol      modity  \n",
       "layers_11_output       capital            sine        ropol      bombed  \n",
       "layers_12_output        busted         конкрет      debuted     instead  \n",
       "layers_13_output             �           人民共和国    provision     instead  \n",
       "layers_14_output            Af      underlying    regarding     instead  \n",
       "layers_15_output    television   authoritative    regarding        swer  \n",
       "layers_16_output   contestants         acronym     -related   therefore  \n",
       "layers_17_output       Dancing   authoritative          nor      uggest  \n",
       "layers_18_output       dancing           stars          nor      please  \n",
       "layers_19_output       Dancing           stars       winner      please  \n",
       "layers_20_output         dance           stars       winner      please  \n",
       "layers_21_output         dance           stars       winner      please  \n",
       "layers_22_output         stars           stars       winner         Can  \n",
       "layers_23_output         stars           stars       winner         Can  \n",
       "layers_24_output           the           Stars            .         Can  \n",
       "layers_25_output           the           Stars            .         Can  \n",
       "layers_26_output           the           stars            .         Can  \n",
       "layers_27_output           the           Stars            .              "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(toks_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a431d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = pd.read_csv('data/rag_routing_eval_dataset.csv')\n",
    "perturbation_context = pd.read_csv('data/rag_routing_eval_dataset_context_perturbations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21f000a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:49,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(eval_dataset.iterrows()):\n",
    "    text_without_context = tokenizer.apply_chat_template([\n",
    "        {\"role\": \"user\", \"content\": row['question']}, \n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant who gives only factually correct short answers without additional information\"}\n",
    "    ], \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    text_with_context = tokenizer.apply_chat_template([\n",
    "        {\"role\": \"user\", \"content\": transfer_context_prompt(row['question'], row['context'])}, \n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant who gives only factually correct short answers without additional information\"}\n",
    "    ], \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    toks_per_layer_without_context = get_activation(text_without_context, model, tokenizer, 16)\n",
    "    pd.DataFrame(toks_per_layer_without_context).to_csv(f'data/tokens_per_layers/normal_context/{index}_without_context.csv')\n",
    "    toks_per_layer_with_context = get_activation(text_with_context, model, tokenizer, 16)\n",
    "    pd.DataFrame(toks_per_layer_with_context).to_csv(f'data/tokens_per_layers/normal_context/{index}_with_context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34d3e4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:16,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(perturbation_context.iterrows()):\n",
    "    text_without_context = tokenizer.apply_chat_template([\n",
    "        {\"role\": \"user\", \"content\": row['question']}, \n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant who gives only factually correct short answers without additional information\"}\n",
    "    ], \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    text_with_context = tokenizer.apply_chat_template([\n",
    "        {\"role\": \"user\", \"content\": transfer_context_prompt(row['question'], row['context_perturbations'])}, \n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant who gives only factually correct short answers without additional information\"}\n",
    "    ], \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    toks_per_layer_without_context = get_activation(text_without_context, model, tokenizer, 16)\n",
    "    pd.DataFrame(toks_per_layer_without_context).to_csv(f'data/tokens_per_layers/bad_context/{index}_without_context.csv')\n",
    "    toks_per_layer_with_context = get_activation(text_with_context, model, tokenizer, 16)\n",
    "    pd.DataFrame(toks_per_layer_with_context).to_csv(f'data/tokens_per_layers/bad_context/{index}_with_context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b54505cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What kind of sports did Mehdi Tahiri do?'\n",
    "context = 'Mehdi Tahiri (born 28 July 1977) is a retired Moroccan tennis player. Tahiri represented Morocco in the Davis Cup in several years from 1993 to 2006.'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": transfer_context_prompt(question, context)}, \n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant who gives only factually correct short answers without additional information\"}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "def track_token_probs(activations, model, tokenizer, target_token_ids):\n",
    "    token_probs = {}\n",
    "    for name, activation in activations.items():\n",
    "        lm_head_out = model.lm_head(model.model.norm(activation))\n",
    "        logits = lm_head_out[:, -1, :]\n",
    "        \n",
    "        token_logits = logits[:, target_token_ids]\n",
    "        token_probs[name] = torch.softmax(token_logits, dim=-1).squeeze().tolist()\n",
    "        \n",
    "    return token_probs\n",
    "\n",
    "def get_activation(input_text, model, tokenizer, top_k=5):\n",
    "    device = model.device\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    input_ids, attention_mask = inputs[\"input_ids\"].to(device), inputs[\"attention_mask\"].to(device)\n",
    "    \n",
    "    activations = {}\n",
    "    \n",
    "    def getActivation(name, activations):\n",
    "        def hook(model, input, output):\n",
    "            activations[name + \"_output\"] = output[0].detach()\n",
    "        return hook\n",
    "    \n",
    "    h = [\n",
    "        model.model.layers[i].register_forward_hook(getActivation(f\"layers_{i}\", activations)) \n",
    "        for i in range(model.config.num_hidden_layers)\n",
    "    ]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = out.logits\n",
    "    last_layer_logits = logits[:, -1, :]\n",
    "    \n",
    "    top_k_probs, top_k_indices = torch.topk(last_layer_logits, k=top_k, dim=-1)\n",
    "    top_tokens = tokenizer.batch_decode(top_k_indices.squeeze().tolist(), skip_special_tokens=True)\n",
    "    \n",
    "    target_token_ids = top_k_indices.squeeze().tolist()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    token_probs_by_layer = track_token_probs(activations, model, tokenizer, target_token_ids)\n",
    "    \n",
    "    [hook.remove() for hook in h]\n",
    "    \n",
    "    return {\"top_tokens\": top_tokens, \"probabilities_by_layer\": token_probs_by_layer}\n",
    "\n",
    "toks_per_layer = get_activation(text, model, tokenizer, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9aaaf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_tokens': ['T', 'He', 'M', 'Mor', 'ten'],\n",
       " 'probabilities_by_layer': {'layers_0_output': [0.1431712508201599,\n",
       "   0.14148534834384918,\n",
       "   0.34414049983024597,\n",
       "   0.20533457398414612,\n",
       "   0.16586826741695404],\n",
       "  'layers_1_output': [0.16472505033016205,\n",
       "   0.09690017998218536,\n",
       "   0.41285625100135803,\n",
       "   0.1934746950864792,\n",
       "   0.1320437639951706],\n",
       "  'layers_2_output': [0.12963250279426575,\n",
       "   0.03474211320281029,\n",
       "   0.5197805166244507,\n",
       "   0.2575804889202118,\n",
       "   0.05826433748006821],\n",
       "  'layers_3_output': [0.03574942797422409,\n",
       "   0.06761986762285233,\n",
       "   0.6824180483818054,\n",
       "   0.17775548994541168,\n",
       "   0.036457162350416183],\n",
       "  'layers_4_output': [0.14672821760177612,\n",
       "   0.41593456268310547,\n",
       "   0.12328041344881058,\n",
       "   0.2801649570465088,\n",
       "   0.03389190882444382],\n",
       "  'layers_5_output': [0.4567137658596039,\n",
       "   0.037576451897621155,\n",
       "   0.2526184618473053,\n",
       "   0.23385019600391388,\n",
       "   0.019241120666265488],\n",
       "  'layers_6_output': [0.24742604792118073,\n",
       "   0.016151955351233482,\n",
       "   0.15686658024787903,\n",
       "   0.4432472288608551,\n",
       "   0.13630816340446472],\n",
       "  'layers_7_output': [0.10462283343076706,\n",
       "   0.14146515727043152,\n",
       "   0.24853965640068054,\n",
       "   0.4838152229785919,\n",
       "   0.02155715599656105],\n",
       "  'layers_8_output': [0.028206845745444298,\n",
       "   0.5285671353340149,\n",
       "   0.03686895966529846,\n",
       "   0.3833589255809784,\n",
       "   0.022998126223683357],\n",
       "  'layers_9_output': [0.02917838841676712,\n",
       "   0.5508065819740295,\n",
       "   0.035273127257823944,\n",
       "   0.3113086223602295,\n",
       "   0.07343331724405289],\n",
       "  'layers_10_output': [0.09393848478794098,\n",
       "   0.29365891218185425,\n",
       "   0.06099304184317589,\n",
       "   0.4855538010597229,\n",
       "   0.06585584580898285],\n",
       "  'layers_11_output': [0.0035394197329878807,\n",
       "   0.04453563690185547,\n",
       "   0.03027503378689289,\n",
       "   0.9166877865791321,\n",
       "   0.004962107166647911],\n",
       "  'layers_12_output': [0.020784014835953712,\n",
       "   0.09674833714962006,\n",
       "   0.3663748800754547,\n",
       "   0.49563097953796387,\n",
       "   0.02046184614300728],\n",
       "  'layers_13_output': [0.026699021458625793,\n",
       "   0.12087374925613403,\n",
       "   0.5663700699806213,\n",
       "   0.23440977931022644,\n",
       "   0.0516473762691021],\n",
       "  'layers_14_output': [0.03404166176915169,\n",
       "   0.11337445676326752,\n",
       "   0.49667051434516907,\n",
       "   0.3425680994987488,\n",
       "   0.013345270417630672],\n",
       "  'layers_15_output': [0.2741752564907074,\n",
       "   0.25623205304145813,\n",
       "   0.3125016987323761,\n",
       "   0.10992484539747238,\n",
       "   0.04716617986559868],\n",
       "  'layers_16_output': [0.06949641555547714,\n",
       "   0.33490633964538574,\n",
       "   0.1626642495393753,\n",
       "   0.103758305311203,\n",
       "   0.329174667596817],\n",
       "  'layers_17_output': [0.011940993368625641,\n",
       "   0.20860417187213898,\n",
       "   0.0655478835105896,\n",
       "   0.022726822644472122,\n",
       "   0.6911801099777222],\n",
       "  'layers_18_output': [0.012050146237015724,\n",
       "   0.6253290772438049,\n",
       "   0.059180859476327896,\n",
       "   0.015196098014712334,\n",
       "   0.28824383020401],\n",
       "  'layers_19_output': [0.02453252673149109,\n",
       "   0.09659949690103531,\n",
       "   0.1516122817993164,\n",
       "   0.002742040203884244,\n",
       "   0.7245137095451355],\n",
       "  'layers_20_output': [0.005839094519615173,\n",
       "   0.0019141208613291383,\n",
       "   0.00852223765105009,\n",
       "   7.42271586204879e-05,\n",
       "   0.983650267124176],\n",
       "  'layers_21_output': [0.16010457277297974,\n",
       "   0.0004957414930686355,\n",
       "   0.005824349354952574,\n",
       "   7.578872464364395e-05,\n",
       "   0.833499550819397],\n",
       "  'layers_22_output': [0.03588227927684784,\n",
       "   0.00038850141572766006,\n",
       "   0.0005276800948195159,\n",
       "   0.011970088817179203,\n",
       "   0.9512315988540649],\n",
       "  'layers_23_output': [0.11161145567893982,\n",
       "   0.016055602580308914,\n",
       "   0.002414531074464321,\n",
       "   0.01263635978102684,\n",
       "   0.8572821617126465],\n",
       "  'layers_24_output': [0.1075001060962677,\n",
       "   0.05146974325180054,\n",
       "   0.0008757714531384408,\n",
       "   0.014600737020373344,\n",
       "   0.8255535960197449],\n",
       "  'layers_25_output': [0.8605473637580872,\n",
       "   0.02928774058818817,\n",
       "   0.003719589440152049,\n",
       "   0.0018627704121172428,\n",
       "   0.10458248108625412],\n",
       "  'layers_26_output': [0.6094509959220886,\n",
       "   0.2925868332386017,\n",
       "   0.016671039164066315,\n",
       "   0.002863424364477396,\n",
       "   0.07842767238616943],\n",
       "  'layers_27_output': [0.9882738590240479,\n",
       "   0.0050534033216536045,\n",
       "   0.004037848208099604,\n",
       "   0.0014209356158971786,\n",
       "   0.0012139390455558896]}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aa9c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
